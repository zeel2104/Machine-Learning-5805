---
title: "Blog 4: Classification"
author: "Zeel Desai"
date: "2023-11-26"
categories: [code, data analysis]
image: "image.jpeg"
---

_Decoding Breast Cancer: Machine Learning Strategies for Accurate Classification_

# Breast cancer classification

Breast cancer is a prevalent and potentially life-threatening disease that affects both men and women. Early detection and accurate classification of breast tumors play a crucial role in improving patient outcomes. Machine learning (ML) techniques have emerged as valuable tools in medical diagnostics, particularly in the field of cancer classification.

The objective of breast cancer classification is to distinguish between benign and malignant tumors based on various features extracted from diagnostic tests, such as imaging or biopsy data. Machine learning models leverage these features to predict and classify tumors, aiding medical professionals in making informed decisions about patient treatment and care.



```{python}

#The script starts by importing necessary libraries for data analysis, visualization, and machine learning.
#The breast cancer dataset is loaded from a CSV file using pandas.
#The 'id' column is dropped from the dataset.
#+The script checks for missing values in the dataset and visualizes the data distribution with histograms.

# Import Libary
import numpy as np # linear algebra
import pandas as pd # data processing

# Libraries for visualization:
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
from plotly.offline import init_notebook_mode, iplot
init_notebook_mode(connected = True)
from plotly.subplots import make_subplots

import warnings
warnings.filterwarnings("ignore")

```

```{python}
data=pd.read_csv("breast-cancer.csv")


data.head()
```

```{python}
# Download and prepare the data
data.drop(["id"],axis=1,inplace=True)
```

Descriptive statistics (mean, min, max, etc.) of the dataset are displayed.
A heatmap is created to show the correlation between different variables in the dataset.

```{python}
data.describe()
```


```{python}
# Check for missing value:
data.isnull().sum()
```

```{python}
data.hist(figsize = (18,17),color = 'orange',edgecolor = 'black');
```


```{python}
# Check strength of the relationship between variables:
corr=data.corr(numeric_only = True)
f,ax=plt.subplots(figsize=(15,15))
sns.heatmap(corr,annot=True,linewidths=0.5,fmt=".1f",ax=ax,cmap="YlGnBu",square=True)
plt.show()
```



```{python}
print('Count of M or B cells in diagnosis:')
data['diagnosis'].value_counts()
```

```{python}
# Plot distribution
data['diagnosis'].value_counts().plot(kind='pie', labels = ['', ''], autopct = '%1.1F%%', colors = ['#9091b1','#e1b0cd'], 
                                    explode = [0,0.05], textprops = {'fontsize':15})
plt.legend(labels=['Benign', 'Malignant'], fontsize=12)
plt.title('Distributions of the target variable\n', fontsize=20, color = '#6a6a6a', y=1.03)
plt.show()
```

```{python}
sns.countplot(x='diagnosis',data=data,palette='Greens_d')
plt.show()

## M for Malignant
## B for Benign
```

```{python}
#Libraries for ML model
from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier
from sklearn.naive_bayes import GaussianNB
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,f1_score,recall_score,precision_score,roc_auc_score
```

```{python}
y=data["diagnosis"]
X=data.drop(["diagnosis"],axis=1)
print("X shape",X.shape)
print("y shape",y.shape)
```



Data Preparation for Machine Learning:

The script prepares the data for machine learning by separating the target variable ('diagnosis') and the features.

The 'LabelBinarizer' is used to convert the categorical target variable into numerical format (0 or 1).

```{python}
one_hot=LabelBinarizer()
y=one_hot.fit_transform(y)
```

```{python}
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=42,shuffle=True)
```

```{python}
print("X_train shape",X_train.shape)
print("y_train shape",y_train.shape)
print("X_test shape",X_test.shape)
print("y_test shape",y_test.shape)
```


### Several classification models are defined and trained on the training data.
### Models include Logistic Regression, K-Nearest Neighbors, Random Forest, XGBoost, Gradient Boosting, Gaussian Naive Bayes, and Decision Tree.
### Evaluation metrics such as Accuracy, ROC-AUC, F1 Score, Precision, and Recall are calculated for each model.
### Results are visualized using a horizontal bar chart for each metric.

```{python}
# Lets create model:
def classification_models(model):
    y_pred=model.fit(X_train,y_train).predict(X_test)
    accuracy=accuracy_score(y_pred,y_test)
    roc_score=roc_auc_score(y_test,y_pred)
    f1=f1_score(y_pred,y_test)
    precision=precision_score(y_pred,y_test)
    recall=recall_score(y_pred,y_test)
    
    results=pd.DataFrame({"Values":[accuracy,roc_score,f1,precision,recall],
                         "Metrics":["Accuracy","ROC-AUC","F1","Precision","Recall"]})
    
    # Visualize Results:
    fig=make_subplots(rows=1,cols=1)
    fig.add_bar(x=[round(i,5) for i in results["Values"]],
                        y=results["Metrics"],
                        text=[round(i,5) for i in results["Values"]],orientation="h",textposition="inside",name="Values",
                        marker=dict(color=["khaki","bisque","palegreen","skyblue","plum"],line_color="beige",line_width=1.5),row=1,col=1)
    fig.update_layout(title={'text': model.__class__.__name__ ,
                             'y':0.9,
                             'x':0.5,
                             'xanchor': 'center',
                             'yanchor': 'top'},
                      template='plotly_white')
    fig.update_xaxes(range=[0,1], row = 1, col = 1)
    
    iplot(fig)
    
my_models= [
    
    LogisticRegression(),
    KNeighborsClassifier(),
    RandomForestClassifier(),
    XGBClassifier(),
    GradientBoostingClassifier(),
    GaussianNB(),
    DecisionTreeClassifier()


]

for model in my_models:
    classification_models(model)

```


*********

Conclusion

In conclusion, breast cancer prediction through classification using machine learning is a dynamic and evolving field with the potential to significantly impact patient care. The collaborative efforts of interdisciplinary teams, coupled with advancements in technology and data science, contribute to the ongoing improvement of models for breast cancer detection and classification. While these models provide valuable support, they are most effective when used in conjunction with the expertise and judgment of healthcare professionals in the diagnosis and treatment of breast cancer.






